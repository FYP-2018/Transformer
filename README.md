# Transformer

Implement Transformer

## Run
Execute ```main.py``` to run the model


## Reference Paper: 
1. Attention is all you need

## Future Implementation:
1. Decoder-only transformer (code finished, havent tested on gpu) 
2. Sliding window version
3. Segmened attention (local attention) 
4. Randomly chosen attention 